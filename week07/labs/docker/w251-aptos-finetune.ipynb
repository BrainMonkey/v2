{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "#print(os.listdir(\"../input\"))\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "#import seaborn as sns\n",
    "import random\n",
    "from apex import amp\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from functools import partial\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "def quadratic_kappa(y_hat, y):\n",
    "    return cohen_kappa_score(np.round(y_hat), y, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_decay = 1e-5\n",
    "# lr          = 1e-4\n",
    "weight_decay = 2e-5\n",
    "lr          = 5e-5\n",
    "\n",
    "# weight_decay = 1e-4\n",
    "# lr          = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "seed_everything(1234)\n",
    "# lr          = 1e-6\n",
    "efficientnet_arch = 'efficientnet-b4'\n",
    "IMG_SIZE    = EfficientNet.get_image_size(efficientnet_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 32\n",
    "val_batch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = '/data/kaggle/aptos/train/images/'\n",
    "train_2015      = '/data/kaggle/aptos/trainold/resized_train_cropped/'\n",
    "#valid      = '/data/aptos/train/images/'\n",
    "test       = '/data/kaggle/aptos/test/images/'\n",
    "\n",
    "# train_csv  = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "\n",
    "### train_csv = pd.read_csv(\"/data/aptos/train.csv\")\n",
    "#train_csv = pd.read_csv(\"/data/aptos/trainboth.csv\")\n",
    "#valdata = pd.read_csv(\"/data/aptos/valboth.csv\")\n",
    "test_df = pd.read_csv(\"/data/kaggle/aptos/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the starting checkpoint\n",
    "# these weights come from pre-training on an equal mix of old and new data\n",
    "minfile = 'gray_all_b4_fixed_lr_1e-4_380.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often do we eval our model?\n",
    "eval_steps = 55\n",
    "# how often do we print the loss?\n",
    "print_steps=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training dataset\n",
    "train_df_1 = pd.read_csv(\"/data/kaggle/aptos/newtrainh.csv\")\n",
    "\n",
    "# the validation dataset\n",
    "val_df_1 = pd.read_csv(\"/data/kaggle/aptos/newvalh.csv\")\n",
    "\n",
    "# uncomment this to train on both\n",
    "# both = []\n",
    "# both.append(train_df_1)\n",
    "# both.append(val_df_1)\n",
    "# train_df = pd.concat(both)\n",
    "# val_df = pd.concat(both)\n",
    "\n",
    "# comment this out if you want to train on both\n",
    "train_df = train_df_1\n",
    "val_df = val_df_1\n",
    "\n",
    "\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.reset_index(drop=True, inplace=True)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_path(p):\n",
    "    p = str(p)\n",
    "    if isfile(train + p + \".png\"):\n",
    "        return train + (p + \".png\")\n",
    "    if isfile(train_2015 + p + '.jpeg'):\n",
    "        return train_2015 + (p + \".jpeg\")\n",
    "    if isfile(test + p + \".png\"):\n",
    "        return test + (p + \".png\")\n",
    "    return p\n",
    "\n",
    "def p_show(imgs, label_name=None, per_row=3):\n",
    "    n = len(imgs)\n",
    "    rows = (n + per_row - 1)//per_row\n",
    "    cols = min(per_row, n)\n",
    "    fig, axes = plt.subplots(rows,cols, figsize=(15,15))\n",
    "    for ax in axes.flatten(): ax.axis('off')\n",
    "    for i,(p, ax) in enumerate(zip(imgs, axes.flatten())): \n",
    "        img = Image.open(expand_path(p))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(train_df[train_df.id_code == p].diagnosis.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = []\n",
    "# for p in train_df.id_code:\n",
    "#     imgs.append(p)\n",
    "#     if len(imgs) == 16: break\n",
    "# p_show(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Code from: https://www.kaggle.com/ratthachat/aptos-updated-albumentation-meets-grad-cam\n",
    "\n",
    "def crop_image1(img,tol=7):\n",
    "    # img is image data\n",
    "    # tol  is tolerance\n",
    "        \n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.df.diagnosis.values[idx]\n",
    "        label = np.expand_dims(label, -1)\n",
    "        \n",
    "        p = self.df.id_code.values[idx]\n",
    "        p_path = expand_path(p)\n",
    "        image = cv2.imread(p_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = crop_image_from_gray(image)\n",
    "        try: \n",
    "          image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        except:\n",
    "            print(\"unable to resize image: \", p_path)\n",
    "#        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation((-120, 120)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation((-120, 120)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset     = MyDataset(train_df, transform =train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch, shuffle=True, num_workers=12)\n",
    "#valset       = MyDataset(val_df, transform   =train_transform)\n",
    "valset       = MyDataset(val_df, transform   =val_transform)\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size=val_batch, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testset       = MyDataset(test_df, transform   =val_transform)\n",
    "#test_loader   = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = EfficientNet.from_name('efficientnet-b0')\n",
    "# model = EfficientNet.from_name('efficientnet-b3')\n",
    "model = EfficientNet.from_name('efficientnet-b4')\n",
    "# model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b3-5fb5a3c3.pth'))\n",
    "#minfile = '/data/models/efficientnet/efficientnet-b3-5fb5a3c3.pth'\n",
    "#minfile = 'nogray_all_b3.pt'\n",
    "\n",
    "# model.load_state_dict(torch.load(minfile))\n",
    "finetune = True\n",
    "# model.load_state_dict(torch.load('../input/efficientnet-pytorch/efficientnet-b0-08094119.pth'))\n",
    "#model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b0-08094119.pth'))\n",
    "#model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b5-586e6cc6.pth'))\n",
    "# model.load_state_dict(torch.load('/data/models/efficientnet/efficientnet-b4-e116e8b3.pth'))\n",
    "\n",
    "if not finetune:\n",
    "  model.load_state_dict(torch.load(minfile))\n",
    "  in_features = model._fc.in_features\n",
    "  model._fc = nn.Linear(in_features, num_classes)\n",
    "else:\n",
    "  in_features = model._fc.in_features\n",
    "  model._fc = nn.Linear(in_features, num_classes)\n",
    "  model.load_state_dict(torch.load(minfile)) \n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.MSELoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    model.train() \n",
    "        \n",
    "    avg_loss = 0.\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.float().cuda()\n",
    "        output_train = model(imgs_train)\n",
    "        loss = criterion(output_train,labels_train)\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "    return avg_loss\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    avg_val_loss = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.float().cuda()\n",
    "            output_test = model(imgs_vaild)\n",
    "            avg_val_loss += criterion(output_test, labels_vaild).item() / len(val_loader)\n",
    "        \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model1(epoch):\n",
    "    model.train() \n",
    "        \n",
    "    avg_loss = 0.\n",
    "    sum_loss = 0.\n",
    "    print_steps_loss_beg= 0\n",
    "    optimizer.zero_grad()\n",
    "    start_time   = time.time()\n",
    "    for idx, (imgs, labels) in enumerate(train_loader):\n",
    "\n",
    "        if idx > 0 and idx % print_steps == 0:\n",
    "\n",
    "            time_per_step   = (time.time() - start_time) / eval_steps\n",
    "            aloss = (sum_loss-print_steps_loss_beg) / print_steps\n",
    "            print('epoch {}, step {}/{}, time/step {:.2f}, loss {:.4f}'.format(epoch, idx, len(train_loader), time_per_step, aloss, TTA))\n",
    "            start_time   = time.time()  \n",
    "            print_steps_loss_beg = sum_loss\n",
    "        \n",
    "        if idx % eval_steps == 0:\n",
    "            print('step {}, running eval with tta {}'.format(idx, TTA))\n",
    "            estart_time   = time.time()\n",
    "#            avg_val_loss1, qk1, coeffs1 = test_model1(val_df1, val_loader1a, model, TTA=TTA)\n",
    "#            avg_val_loss2, qk2, coeffs2 = test_model1(val_df2, val_loader2a, model, TTA=TTA)\n",
    "\n",
    "            avg_val_loss, qk, coeffs = test_model1(val_df, val_loader, model, TTA=TTA)\n",
    "    \n",
    "            etime   = (time.time() - estart_time)\n",
    "            print('lr {:.6f}, vloss {:.4f}, qk {:.4f}, time {:.2f}'.format(lr, avg_val_loss, qk, etime))\n",
    "            print(*coeffs, sep = \", \") \n",
    "#            print(*coeffs2, sep = \", \")\n",
    "            start_time   = time.time()\n",
    "            \n",
    "            mfiled = mfile_base + str(epoch) + \"_\" + str(idx) + '.pt'\n",
    "            torch.save(model.state_dict(), mfiled)\n",
    "            print('saved model ' + mfiled)\n",
    "            \n",
    "            model.train()        \n",
    "        \n",
    "        imgs_train, labels_train = imgs.cuda(), labels.float().cuda()\n",
    "        output_train = model(imgs_train)\n",
    "        loss = criterion(output_train,labels_train)\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        sum_loss += loss.item()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "\n",
    "        \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model1(val_df, val_loader, model, TTA=1):\n",
    "    \n",
    "    test_pred = np.zeros((len(val_df), 1))\n",
    "#    print(\"len val loader: \", len(val_loader))\n",
    "    \n",
    "    avg_val_loss = 0.\n",
    "    model.eval()\n",
    "    \n",
    "    for _ in range(TTA):\n",
    "      with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "#            print(\"idx:\", idx)\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.float().cuda()\n",
    "            output = model(imgs_vaild)\n",
    "            avg_val_loss += criterion(output, labels_vaild).item() / len(val_loader) \n",
    "#            outputlist.append(output_test)\n",
    "            o = output.detach().cpu().squeeze().numpy().reshape(-1, 1)\n",
    "            test_pred[idx*val_batch:(idx + 1)*val_batch] += o\n",
    "    \n",
    "    test_pred = test_pred / TTA   \n",
    "    avg_val_loss = avg_val_loss / TTA\n",
    "    outputlist=test_pred.tolist() \n",
    "    \n",
    "    targets = val_df['diagnosis']\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(outputlist, targets)\n",
    "    coeffs = optR.coefficients()\n",
    "#    print(coefficients)\n",
    "    valid_predictions = optR.predict(outputlist, coeffs)\n",
    "#    valid_predictions\n",
    "    qk = quadratic_kappa(valid_predictions, targets)\n",
    "    \n",
    "    return avg_val_loss, qk, coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfile_base = 'final/b4_finetune_class'\n",
    "TTA=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_loss, qk, coeffs = test_model1(val_df, val_loader, model, TTA=5)\n",
    "print('vloss {:.4f}, qk {:.4f}'.format(avg_val_loss, qk))\n",
    "print(*coeffs, sep = \", \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vloss 0.1897, qk 0.9410\n",
    "0.5327213048934935, 1.3462411880493155, 2.674007296562195, 3.258482289314271\n",
    "\n",
    "vloss 0.1843, qk 0.9443\n",
    "0.5216156987007712, 1.3463758931960894, 2.927448195172474, 3.078980172518639\n",
    "\n",
    "vloss 0.1815, qk 0.9471\n",
    "0.553874470140727, 1.4078223163334747, 2.5334583017684054, 3.120178290446344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_loss, qk, coeffs = test_model1(val_df, val_loader, model, TTA=2)\n",
    "print('vloss {:.4f}, qk {:.4f}'.format(avg_val_loss, qk))\n",
    "print(*coeffs, sep = \", \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_loss, qk, coeffs = test_model1(val_df, val_loader, model, TTA=3)\n",
    "print('vloss {:.4f}, qk {:.4f}'.format(avg_val_loss, qk))\n",
    "print(*coeffs, sep = \", \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_loss, qk, coeffs = test_model1(val_df, val_loader, model, TTA=TTA)\n",
    "print('vloss {:.4f}, qk {:.4f}'.format(avg_val_loss, qk))\n",
    "print(*coeffs, sep = \", \") \n",
    "# TTA 5\n",
    "# vloss 0.1908, qk 0.9293\n",
    "# 0.5070718765258792, 1.454644203186034, 2.343782424926758, 3.7259878158569353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best_avg_loss = 100.0\n",
    "n_epochs      = 2\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('lr:', lr) \n",
    "#    print('lr:', scheduler.get_lr()[0]) \n",
    "    start_time   = time.time()\n",
    "    avg_loss     = train_model1(epoch)\n",
    "#    avg_val_loss = test_model()\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "\n",
    "#    mfile = mfile_base + str(epoch) + '.pt'\n",
    "#    torch.save(model.state_dict(), mfile)\n",
    "#    print('saved model') \n",
    "#    if avg_val_loss < best_avg_loss:\n",
    "#        best_avg_loss = avg_val_loss\n",
    "#        torch.save(model.state_dict(), mfile)\n",
    "#        print('saved model with val loss: {}'.format(avg_val_loss))\n",
    "    \n",
    "#    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_chkpoints = []\n",
    "best_chkpoints.append('final/b4_finetune_class1_0.pt')\n",
    "best_chkpoints.append('final/b4_finetune_class1_100.pt')\n",
    "best_chkpoints.append('final/b4_finetune_class1_0.pt')\n",
    "best_chkpoints.append('final/b4_finetune_class1_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(val_df, val_loader, model, TTA=5):\n",
    "    \n",
    "    test_pred = np.zeros((len(val_df), 1))\n",
    "#    print(\"len val loader: \", len(val_loader))\n",
    "    \n",
    "    avg_val_loss = 0.\n",
    "    model.eval()\n",
    "    \n",
    "    for _ in range(TTA):\n",
    "      with torch.no_grad():\n",
    "        for idx, (imgs, labels) in enumerate(val_loader):\n",
    "#            print(\"idx:\", idx)\n",
    "            imgs_vaild, labels_vaild = imgs.cuda(), labels.float().cuda()\n",
    "            output = model(imgs_vaild)\n",
    "            avg_val_loss += criterion(output, labels_vaild).item() / len(val_loader) \n",
    "#            outputlist.append(output_test)\n",
    "            o = output.detach().cpu().squeeze().numpy().reshape(-1, 1)\n",
    "            test_pred[idx*val_batch:(idx + 1)*val_batch] += o\n",
    "    \n",
    "    test_pred = test_pred / TTA   \n",
    "    avg_val_loss = avg_val_loss / TTA\n",
    "\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num checkpoints: \", len(best_chkpoints))\n",
    "outputs = np.zeros((len(val_df), 1))\n",
    "\n",
    "for m in best_chkpoints:\n",
    "    print(\"processing \", m)\n",
    "#    model = EfficientNet.from_name('efficientnet-b4')\n",
    "#    in_features = model._fc.in_features\n",
    "#    model._fc = nn.Linear(in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(m))\n",
    "#    model = model.half()\n",
    "    outputs += run_model(val_df, val_loader, model, TTA=1)\n",
    "    \n",
    "outputs = outputs / len(best_chkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputlist=outputs.tolist() \n",
    "optR = OptimizedRounder()\n",
    "targets = val_df['diagnosis']\n",
    "optR.fit(outputlist, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = optR.coefficients()\n",
    "print(*coeffs, sep = \", \")\n",
    "#    print(coefficients)\n",
    "valid_predictions = optR.predict(outputlist, coeffs)\n",
    "#    valid_predictions\n",
    "qk = quadratic_kappa(valid_predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"qk is: {:.4f}\".format(qk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
